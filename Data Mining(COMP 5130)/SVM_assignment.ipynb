{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# README\n",
        "\n",
        "The only dependencies that are required are the following libraries: NumPy, Matplotlib, CVXOPT, and Scikit-Learn.\n",
        "\n",
        "The notebook needs the following files to run: banana_quality.csv and banknoteAuthentication.csv."
      ],
      "metadata": {
        "id": "ogt2AQZ2uBmK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWiUlR4qncw8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from cvxopt import matrix, solvers\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Soft Margin SVM class\n",
        "class SVM_Soft_Margin:\n",
        "  def __init__(self, feature_matrix, labels, C = None, w = None, b = None):\n",
        "    self.feature_matrix = feature_matrix.astype(np.float64)\n",
        "    self.labels = labels.astype(np.float64)\n",
        "    self.num_examples = np.shape(feature_matrix)[0]\n",
        "    self.num_features = np.shape(feature_matrix)[1]\n",
        "    self.C = C\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "    self.accuracy = 0\n",
        "    self.size_of_margin = 0\n",
        "    self.support_vectors = None\n",
        "    self.predictions = None\n",
        "\n",
        "  def train_SVM(self):\n",
        "    dot_product_features_matrix = np.dot(self.feature_matrix, self.feature_matrix.T)\n",
        "    dot_product_labels_matrix = np.dot(self.labels, self.labels.T)\n",
        "\n",
        "    # Necessary variables to compute the solution to the dual problem\n",
        "    P = matrix(np.multiply(dot_product_labels_matrix, dot_product_features_matrix))\n",
        "    q = matrix(np.ones((self.num_examples, 1)) * -1)\n",
        "    A = matrix(self.labels.reshape(1, -1), tc = \"d\")\n",
        "    b = matrix(np.zeros(1))\n",
        "    G = matrix(np.vstack((np.identity(self.num_examples) * -1, np.identity(self.num_examples))))\n",
        "    h = matrix(np.hstack((np.zeros(self.num_examples), np.ones(self.num_examples) * self.C)))\n",
        "\n",
        "    # Solves dual problem\n",
        "    solution = solvers.qp(P, q, G, h, A, b)\n",
        "    alphas = np.array(solution['x']).flatten()\n",
        "\n",
        "    # Find the support vectors, these are the points with the largest lagrange multipliers\n",
        "    index_of_svs = np.argpartition(alphas, -2)[-2:]\n",
        "    self.support_vectors = self.feature_matrix[index_of_svs]\n",
        "\n",
        "    # Finds the points that have lagrange multipliers over a certain threshold\n",
        "    # Used these points to find the weights and bias\n",
        "    index_threshold = (alphas > 1e-4).flatten()\n",
        "    alphas_threshold = alphas[index_threshold].reshape(-1 ,1)\n",
        "    svms_threshold = self.feature_matrix[index_threshold]\n",
        "    svms_threshold_labels = self.labels[index_threshold].reshape(-1 ,1)\n",
        "\n",
        "    self.w = np.dot((alphas_threshold * svms_threshold_labels).T, svms_threshold)\n",
        "    self.b = np.mean(svms_threshold_labels - np.dot(self.w, svms_threshold.T))\n",
        "\n",
        "    # Find the margin\n",
        "    self.size_of_margin = 2 / np.linalg.norm(self.w)\n",
        "\n",
        "    # Call the predict function to predict the labels of the data points and find the accuracy\n",
        "    self.predict()\n",
        "\n",
        "  def test_SVM(self):\n",
        "\n",
        "    # Calls the predict function\n",
        "    self.predict()\n",
        "\n",
        "  def find_accuracy(self):\n",
        "    comparison = self.predictions.flatten() == self.labels.flatten()\n",
        "    same_elements = np.count_nonzero(comparison)\n",
        "    self.accuracy = same_elements / self.num_examples\n",
        "\n",
        "  def predict(self):\n",
        "    predictions = np.dot(self.w, self.feature_matrix.T) + self.b\n",
        "    self.predictions = np.sign(predictions)\n",
        "    self.find_accuracy()\n",
        "\n",
        "  def plot_2d(self, x_label, y_label, title):\n",
        "\n",
        "    if self.num_features != 2:\n",
        "      print(\"Data does not have only two features.\")\n",
        "      return\n",
        "\n",
        "    # Finds the slope and intercept for our decision boundary\n",
        "    decision_boundary_slope = -self.w[0][0] / self.w[0][1]\n",
        "    decision_boundary_intercept = -self.b / self.w[0][1]\n",
        "\n",
        "    # Find the intercept for our support vector boundaries\n",
        "    boundary_one_intecept = (1-self.b) / self.w[0][1]\n",
        "    boundary_two_intercept = (-1-self.b) / self.w[0][1]\n",
        "\n",
        "    # Plots all the data points\n",
        "    plt.scatter(self.feature_matrix[:, 0], self.feature_matrix[:, 1])\n",
        "\n",
        "    # Find the x values that are in the range of our data to plot our three boundaries\n",
        "    x_values = range(int(np.min(self.feature_matrix[:, 0])), int(np.max(self.feature_matrix[:, 0])) + 1)\n",
        "\n",
        "    # Finds the corresponding y values for each line\n",
        "    y_values_1 = [decision_boundary_slope * x + decision_boundary_intercept for x in x_values]\n",
        "    y_values_2 = [decision_boundary_slope * x + boundary_one_intecept for x in x_values]\n",
        "    y_values_3 = [decision_boundary_slope * x + boundary_two_intercept for x in x_values]\n",
        "\n",
        "    # Plots the lines\n",
        "    plt.plot(x_values, y_values_1, label='Decision Boundary', color = \"Red\")\n",
        "    plt.plot(x_values, y_values_2, label='Support Vector Boundary One', color = \"Red\", linestyle = \"--\")\n",
        "    plt.plot(x_values, y_values_3, label='Support Vector Boundary Two', color = \"Red\", linestyle = \"--\")\n",
        "\n",
        "    # Plots the support vectors green\n",
        "    plt.scatter(self.support_vectors[:, 0], self.support_vectors[:, 1], color = \"green\", label = \"Support Vectors\")\n",
        "\n",
        "    # Add labels and legend\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "\n",
        "    # Show plot\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LBtrQi-2PAV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates Linearly Separable Dummy Data to show example\n",
        "data, labels = make_blobs(n_samples=200, centers=2, cluster_std=2, random_state = 32)\n",
        "\n",
        "# Plot Data\n",
        "plt.scatter(data[:, 0], data[:, 1])\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Plot of Dummy Data\")\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Renames all the labels of the 0 class to -1\n",
        "labels[labels == 0] = -1\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# Set Apart Training Data\n",
        "training_feature_matrix = data[:180, :]\n",
        "training_labels = labels[:180, :]\n",
        "\n",
        "# Set Apart Test Data\n",
        "testing_feature_matrix = data[180:, :]\n",
        "testing_labels = labels[180:, :]\n"
      ],
      "metadata": {
        "id": "G7CYuEfJn9Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SVM instance for training\n",
        "training_SVM = SVM_Soft_Margin(training_feature_matrix, training_labels, 1)\n",
        "\n",
        "# Train SVM then predict on training data\n",
        "training_SVM.train_SVM()\n",
        "\n",
        "# Print accuracy of training data\n",
        "print(\"Training Accuracy\")\n",
        "print(training_SVM.accuracy)\n",
        "\n",
        "# Call the function to plot our training data\n",
        "training_SVM.plot_2d(\"X\", \"Y\", \"Support Vector Plot\")\n",
        "\n",
        "# Create SVM instance for testing\n",
        "testing_SVM = SVM_Soft_Margin(testing_feature_matrix, testing_labels, w = training_SVM.w, b = training_SVM.b)\n",
        "\n",
        "# Test the SVM\n",
        "testing_SVM.test_SVM()\n",
        "\n",
        "# Print accuracy of testing data\n",
        "print(\"Testing Accuracy\")\n",
        "print(testing_SVM.accuracy)"
      ],
      "metadata": {
        "id": "juCigwXIcKs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bananas Quality Dataset"
      ],
      "metadata": {
        "id": "Y07Zl1l-68ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bananas Dataset\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv('banana_quality.csv')\n",
        "\n",
        "# Save headers\n",
        "features = df.columns.tolist()\n",
        "\n",
        "# Extract data from data frame\n",
        "data = df.values\n",
        "\n",
        "# Shuffle data\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Select only the first 100 examples\n",
        "data = data[:1000, :]\n",
        "\n",
        "# Create feature matrix\n",
        "feature_matrix = data[:, :-1]\n",
        "\n",
        "# Create labels\n",
        "labels = data[:, -1]\n",
        "\n",
        "# Make the labels with the label good to 1 and the labels with the label bad -1\n",
        "labels[labels == \"Good\"] = 1\n",
        "labels[labels == \"Bad\"] = -1\n",
        "\n",
        "# Reshape the labels to column vector\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# Separate data into training and testing, 80 20 split\n",
        "training_feature_matrix, testing_feature_matrix, training_labels, testing_labels = train_test_split(feature_matrix, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7hCRP64dapRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing Bananas Dataset\n",
        "\n",
        "# Create SVM instance for training\n",
        "training_SVM_Bananas = SVM_Soft_Margin(training_feature_matrix, training_labels, .01)\n",
        "\n",
        "# Train SVM then predict on training data\n",
        "training_SVM_Bananas.train_SVM()\n",
        "\n",
        "# Print accuracy of training data\n",
        "print(\"Training Accuracy\")\n",
        "print(training_SVM_Bananas.accuracy)\n",
        "\n",
        "# Create SVM instance for testing\n",
        "testing_SVM_Bananas = SVM_Soft_Margin(testing_feature_matrix, testing_labels, w = training_SVM_Bananas.w, b = training_SVM_Bananas.b)\n",
        "\n",
        "# Test the SVM\n",
        "testing_SVM_Bananas.test_SVM()\n",
        "\n",
        "# Print accuracy of testing data\n",
        "print(\"Testing Accuracy\")\n",
        "print(testing_SVM_Bananas.accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "EPugEBGvktOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Banknote Authentication Dataset"
      ],
      "metadata": {
        "id": "Vk5c7N336uoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Banknote Dataset\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_csv('banknoteAuthentication.csv')\n",
        "\n",
        "# Save headers\n",
        "features = df.columns.tolist()\n",
        "\n",
        "# Extract data from data frame\n",
        "data = df.values\n",
        "\n",
        "# Shuffle data\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Select only the first 100 examples\n",
        "data = data[:1000, :]\n",
        "\n",
        "# Create feature matrix\n",
        "feature_matrix = data[:, :-1]\n",
        "\n",
        "# Create labels\n",
        "labels = data[:, -1]\n",
        "\n",
        "# Make the examples with the label 1 to 1 and the examples with the label 0 to -1\n",
        "labels[labels == 1] = 1\n",
        "labels[labels == 0] = -1\n",
        "\n",
        "# Reshape the labels to column vector\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# Separate data into training and testing, 80 20 split\n",
        "training_feature_matrix, testing_feature_matrix, training_labels, testing_labels = train_test_split(feature_matrix, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "q3jNOSLV6uBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing Banknote Authentication Dataset\n",
        "\n",
        "# Create SVM instance for training\n",
        "training_SVM_Banknote = SVM_Soft_Margin(training_feature_matrix, training_labels, 1)\n",
        "\n",
        "# Train SVM then predict on training data\n",
        "training_SVM_Banknote.train_SVM()\n",
        "\n",
        "# Print accuracy of training data\n",
        "print(\"Training Accuracy\")\n",
        "print(training_SVM_Banknote.accuracy)\n",
        "\n",
        "# Create SVM instance for testing\n",
        "testing_SVM_Banknote = SVM_Soft_Margin(testing_feature_matrix, testing_labels, w = training_SVM_Banknote.w, b = training_SVM_Banknote.b)\n",
        "\n",
        "# Test the SVM\n",
        "testing_SVM_Banknote.test_SVM()\n",
        "\n",
        "# Print accuracy of testing data\n",
        "print(\"Testing Accuracy\")\n",
        "print(testing_SVM_Banknote.accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "YvH75KZ_7C2p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}